 GoogLeNet



Yolo 논문기준
이미지를 7x7그리드로 분할함 -> 
그리드별로 2개의 바운딩 박스를 가지게 함 -> 
그러고 cnn + fnn을 통과시시키면 각 그리드의 바운딩들의 
(위치정보 + 거기 잇을확률 + 어떤 클래스인지 확률) 
이걸 아웃풋으로 제공함 이 과정을 반복
 





CNN
일반 DNN은 기본적으로 1차원 형태의 데이터를 사용합니다. 
때문에 (예를들면 1028x1028같은 2차원 형태의)이미지가 입력값이 되는 경우, 
이것을 flatten시켜서 한줄 데이터로 만들어야 하는데 
이 과정에서 이미지의 공간적/지역적 정보(spatial/topological information)가 손실되게 됩니다. 
또한 추상화과정 없이 바로 연산과정으로 넘어가 버리기 때문에 학습시간과 능률의 효율성이 저하됩니다.


Convolution

그림과 같이 커널(kernel) 또는 필터(filter) 라는 임의의 크기의 행렬로 
높이 너비 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서  
크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 
모두 더한 값을 출력으로 하는 것을 말합니다. 
합성곱 연산을 통해 얻은 특성 맵은 다층 퍼셉트론때와 마찬가지로 비선형성 추가를 위해서 활성화 함수를 지나게 됩니다. 
이때 ReLU 함수나 ReLu 함수의 변형들이 주로 사용됩니다.
다른 활성화 함수에 비해 학습이 빠르고 연산비용이 크지 않고 구현이 매우 간단함

Stride 
Filter의 이동 범위를 스트라이드(stride)라고 합니다.

Padding 
합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아진다는 특징이 있습니다. 
만약, 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성 맵은 초기 입력보다 매우 작아진 상태가 되버립니다. 
합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩(padding)을 사용하면 됩니다.

Pooling
합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적입니다. 
풀링 층에서는 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산이 이루어집니다. 
풀링 연산에는 일반적으로 최대 풀링(max pooling)과 평균 풀링(average pooling)이 사용됩니다. 

Yolo

Yolo 논문기준
이미지를 7x7그리드로 분할함 -> 
그리드별로 2개의 바운딩 박스를 가지게 함 -> 
그러고 cnn과 Fully connected network를 통과시시키면 각 그리드의 바운딩 박스들의 
(위치정보 + 거기 잇을확률 + 어떤 클래스인지 확률) 
이걸 아웃풋으로 제공함 이 아웃풋의 오차를 수정함
이 과정을 반복

https://keyog.tistory.com/30 //  yolov5 CSPNet : CNN의 학습능력 향상 



input data

all images 1920x1200 or 512x512


